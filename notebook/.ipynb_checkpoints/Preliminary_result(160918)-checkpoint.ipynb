{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do list: https://docs.google.com/document/d/1lLPy8CsYQXWQqpdLS9u5O1ga9l-3vCMluFO6sUckkts\n",
    "\n",
    "### 연구 목적: Indoor moving patterns을 이용하여 revisit intention을 예측.\n",
    "\n",
    "크롤링한 User들의 Wi-Fi log을, moving pattern별로 indexing한 후, 적합한 feature들을 선별하여, 어떤 moving pattern이 추후 customer revisit과 관련이 있는지 분석하고자 함.\n",
    "\n",
    "#### Feature description:\n",
    "특정 moving pattern의 revisit intention을 예측하는 supervised learning(classification) 모델에 이용될 feature들\n",
    "\n",
    "**1. Feature 1 (History)**\n",
    "    1. 해당 moving pattern이 일어난 시점까지 customer가 방문한 횟수: new_visit_count\n",
    "**2. Feature 2-7 (Basic stats)**\n",
    "    2. 해당 moving pattern에서 Wi-Fi에 연결된 area의 총 개수: num_logs\n",
    "    3. 해당 moving pattern에서 Wi-Fi에 잡힌 총 시간(중복 포함 - 특정 시점에 다수의 Wi-Fi에 연결할 경우 시간을 모두 합함): total_dwell_time\n",
    "    4. 해당 moving pattern에서 dwell_time > 100인 indoor area(stay point) 개수: num_sp_100\n",
    "    5. 해당 moving pattern에서 customer가 방문한 indoor area의 총 개수 중에서 dwell_time > 100인 확률(방문한 area 중에서 stay point가 차지하는 비율): prob_dwell_100\n",
    "    6. 해당 moving pattern에서 stay points에서 보낸 시간의 합(중복 포함 - 특정 시점에 다수의 Wi-Fi에 연결할 경우 시간을 모두 합함): time_sp_100\n",
    "    7. 해당 moving pattern에서 dwell_time > 100인 indoor area들의 variance: std_sp_100\n",
    "**3. Feature 8-14**\n",
    "    8. 해당 moving pattern이 발생한 요일(Categorical variable): One-hot-encoding을 이용하여 Mon-Sun 7개의 feature(binary variable)로 표현\n",
    "**4. Feature 15-137 (Trajectory)**\n",
    "    9. Trajectory의 uni-gram, bi-gram features ('1f', '1f 1f', '1f 1f-inner', '1f 1f-left', '1f 1f-right', '1f 2f' ...) - 해당 moving pattern에 각 unigram 및 bigram이 몇 번 나왔는지 카운트\n",
    "\n",
    "\n",
    "#### Details\n",
    "1. Moving pattern: 한 유저가 하루 동안 매장 안에서 돌아다닌 와이파이 로그\n",
    "2. Simple trajectory: Moving pattern에서 area를 시간 순서대로 나열한 sequence  (e.g., out,in,b1,b1-left-1,1f,out,in,b1-left)\n",
    "2. Raw data의 경우 wi-fi에 찍힌 로그(어떤 device_id가 어떤 장소의 wi-fi 수신기에 몇시부터 몇초간 접속중이었고, 직원인지의 여부와, 현재까지의 revisit count와 가장 최근의 revisit interval)가 하나의 row로 이루어져 있다. 고로, 하나의 moving pattern에 대한 log가 여러 개로 이루어져 있는데, 로그의 날짜와 device_id를 조합하여 key로 삼고 aggregate하여 하나의 moving pattern이 하나의 row로 나타낼 수 있도록 함)\n",
    "3. Raw data의 revisit_count 데이터를 보면 꼬인 경우가 많았다, 같은 device_id인데 오늘까지 revisit count가 69였는데 그다음날 7이 된다거나, 그래서 이 데이터를 이용하지 않고 새로 카운트해 주었다.\n",
    "4. revisit_intention은 binary variable이며 우리가 예측하고자 하는 label이다, 매장 방문 이후 n일 (n=90) 이내에 다시 매장 방문 내역이 있다면 revisit_intention = 1 로 표시해 주었다.\n",
    "5. 매장 방문의 정의: 특정 일에 특정 유저의 moving pattern이 out으로만 이루어진 로그가 아니면 매장을 방문하였다고 함. out만 여러번 있는 로그의 경우는 지나가는 행인이라고 생각하여 매장을 방문하지 않았다고 간주. (매장 방문 예시1: out,in,1f,1f-right  매장 방문 예시2: out,1f,1f-right,1f,out,2f,1f)\n",
    "6. 따라서 어떤 유저의 timestamp가 가장 오래 된 방문을 가장 첫 방문이라고 가정하고, 그 다음 매장 방문이 발생하면 revisit_count를 1씩 더해 주었다, 이 때 각 방문 사이의 간격은 적어도 1일 이상이다. revisit_count는 각 방문 패턴의 history 정보를 누락시키지 않는다는 목적으로 feature로 삼기로 했다.\n",
    "7. 참고: User-ID별로 indexing해서 유저별 revisit_count를 naive하게 예측한 이전 모델은 supervised_model(basic_features).ipynb 에 정리\n",
    "\n",
    "#### 데이터\n",
    "1. 786번 매장(코오롱 문정직영점) 데이터\n",
    "    1. 직원이라고 한번이라도 로그에 찍힌 device_id는 제거\n",
    "    2. 자주 방문하는 유저(단골 or 택배기사)의 moving pattern을 고려하지 않기 위해, 재방문 횟수가 3번 이하인 유저의 moving pattern만 분석\n",
    "    3. 각 moving pattern별로 재인덱싱 이후 세어본 정식매장 방문 횟수(traj에 in을 포함한 경우) 22,642개(0: 19,953 vs 1: 2,689, revisit_intention 여부) \n",
    "    4. 위 데이터의 revisit intention label 비율을 50:50로 조절한 총 5,378개(0: 2,689 vs 1: 2,689)의 moving patterns을 최종으로 이용함.\n",
    "\n",
    "####  Preliminary results\n",
    "<pre>\n",
    "* 10-fold CV 결과의 평균값\n",
    "    Accuracy\n",
    "      * 3 Nearest Neighbors 0.518\n",
    "      * Decision Tree 0.617\n",
    "      * Random Forest 0.595\n",
    "      * AdaBoost 0.622\n",
    "      * Naive Bayes 0.567\n",
    "      * Logistic Regression 0.583\n",
    "    Precision\n",
    "      * 3 Nearest Neighbors 0.519\n",
    "      * Decision Tree 0.626\n",
    "      * Random Forest 0.618\n",
    "      * AdaBoost 0.643\n",
    "      * Naive Bayes 0.64\n",
    "      * Logistic Regression 0.596\n",
    "    Recall\n",
    "      * 3 Nearest Neighbors 0.512\n",
    "      * Decision Tree 0.586\n",
    "      * Random Forest 0.519\n",
    "      * AdaBoost 0.55\n",
    "      * Naive Bayes 0.308\n",
    "      * Logistic Regression 0.514\n",
    "    F1\n",
    "      * 3 Nearest Neighbors 0.515\n",
    "      * Decision Tree 0.604\n",
    "      * Random Forest 0.583\n",
    "      * AdaBoost 0.592\n",
    "      * Naive Bayes 0.416\n",
    "      * Logistic Regression 0.552\n",
    "    ROC-AUC\n",
    "      * 3 Nearest Neighbors 0.52\n",
    "      * Decision Tree 0.65\n",
    "      * Random Forest 0.636\n",
    "      * AdaBoost 0.659\n",
    "      * Naive Bayes 0.608\n",
    "      * Logistic Regression 0.608\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 각 moving pattern별로 재인덱싱한 데이터 로드\n",
    "trajs_combined = pd.read_pickle(\"../data/786/786_trajs_combined.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22642, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device_id</th>\n",
       "      <th>traj</th>\n",
       "      <th>new_visit_count</th>\n",
       "      <th>num_logs</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>num_sp_100</th>\n",
       "      <th>prob_dwell_100</th>\n",
       "      <th>time_sp_100</th>\n",
       "      <th>std_sp_100</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>revisit_intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16675_02614c7588f7f8eaa0d3b9047ac08410</th>\n",
       "      <td>16675.0</td>\n",
       "      <td>02614c7588f7f8eaa0d3b9047ac08410</td>\n",
       "      <td>out,in,1f,1f-right,2f-left,2f,2f-right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1267</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>354.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675_028a1f4dbca00ed06814fdda60f1b599</th>\n",
       "      <td>16675.0</td>\n",
       "      <td>028a1f4dbca00ed06814fdda60f1b599</td>\n",
       "      <td>out,in,3f,2f,2f-right,2f-inner,2f-left,1f,1f-r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>7139</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3553.0</td>\n",
       "      <td>362.141251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675_062c73a8b307fd05f6af2472a35671ef</th>\n",
       "      <td>16675.0</td>\n",
       "      <td>062c73a8b307fd05f6af2472a35671ef</td>\n",
       "      <td>out,in,1f,1f-inner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2189</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675_06c041f68ec481883941d47d99d6903f</th>\n",
       "      <td>16675.0</td>\n",
       "      <td>06c041f68ec481883941d47d99d6903f</td>\n",
       "      <td>out,in,3f,in,1f,out</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4259</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>159.307878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675_0a47ed78e921824cf54dddcf49ae2911</th>\n",
       "      <td>16675.0</td>\n",
       "      <td>0a47ed78e921824cf54dddcf49ae2911</td>\n",
       "      <td>out,in</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           date  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410  16675.0   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599  16675.0   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef  16675.0   \n",
       "16675_06c041f68ec481883941d47d99d6903f  16675.0   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911  16675.0   \n",
       "\n",
       "                                                               device_id  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410  02614c7588f7f8eaa0d3b9047ac08410   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599  028a1f4dbca00ed06814fdda60f1b599   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef  062c73a8b307fd05f6af2472a35671ef   \n",
       "16675_06c041f68ec481883941d47d99d6903f  06c041f68ec481883941d47d99d6903f   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911  0a47ed78e921824cf54dddcf49ae2911   \n",
       "\n",
       "                                                                                     traj  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410             out,in,1f,1f-right,2f-left,2f,2f-right   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599  out,in,3f,2f,2f-right,2f-inner,2f-left,1f,1f-r...   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef                                 out,in,1f,1f-inner   \n",
       "16675_06c041f68ec481883941d47d99d6903f                                out,in,3f,in,1f,out   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911                                             out,in   \n",
       "\n",
       "                                        new_visit_count  num_logs  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410              1.0         7   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599              1.0        11   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef              1.0         4   \n",
       "16675_06c041f68ec481883941d47d99d6903f              1.0         6   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911              1.0         2   \n",
       "\n",
       "                                        total_dwell_time  num_sp_100  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410              1267         3.0   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599              7139         7.0   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef              2189         2.0   \n",
       "16675_06c041f68ec481883941d47d99d6903f              4259         4.0   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911              2636         1.0   \n",
       "\n",
       "                                        prob_dwell_100  time_sp_100  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410        0.500000        354.0   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599        0.700000       3553.0   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef        0.666667       1130.0   \n",
       "16675_06c041f68ec481883941d47d99d6903f        1.000000       1286.0   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911        1.000000        457.0   \n",
       "\n",
       "                                        std_sp_100  Fri  Mon  Sat  Sun  Thu  \\\n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410   10.000000  1.0  0.0  0.0  0.0  0.0   \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599  362.141251  1.0  0.0  0.0  0.0  0.0   \n",
       "16675_062c73a8b307fd05f6af2472a35671ef    0.000000  1.0  0.0  0.0  0.0  0.0   \n",
       "16675_06c041f68ec481883941d47d99d6903f  159.307878  1.0  0.0  0.0  0.0  0.0   \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911         NaN  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                        Tue  Wed  revisit_intention  \n",
       "16675_02614c7588f7f8eaa0d3b9047ac08410  0.0  0.0                0.0  \n",
       "16675_028a1f4dbca00ed06814fdda60f1b599  0.0  0.0                0.0  \n",
       "16675_062c73a8b307fd05f6af2472a35671ef  0.0  0.0                0.0  \n",
       "16675_06c041f68ec481883941d47d99d6903f  0.0  0.0                0.0  \n",
       "16675_0a47ed78e921824cf54dddcf49ae2911  0.0  0.0                1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trajs_combined.shape)\n",
    "trajs_combined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisit intention이 있는 경우와 없는 경우 모두 비슷한 trajectories를 가지고 있어서, history를 고려하지 않는다고 할 때, indoor moving pattern만으로 classification이 가능할 지 걱정이 된다 (아래 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 trajectories with revisit intention in 3 months\n",
      " out,in,1f             335\n",
      "out,in                228\n",
      "out,in,2f              92\n",
      "out,in,1f,1f-right     78\n",
      "out,in,1f,out          69\n",
      "out,out,in,1f          59\n",
      "out,in,1f-right,1f     47\n",
      "out,out,in             40\n",
      "out,in,out             38\n",
      "out,in,1f,1f-inner     32\n",
      "Name: traj, dtype: int64\n",
      " \n",
      "Top 10 trajectories with no revisit intention in 3 months\n",
      " out,in,1f             3078\n",
      "out,in                2196\n",
      "out,in,2f              794\n",
      "out,in,1f,out          663\n",
      "out,in,1f,1f-right     624\n",
      "out,out,in,1f          565\n",
      "out,in,out             446\n",
      "out,out,in             435\n",
      "out,in,1f-right,1f     296\n",
      "out,in,1f,1f-inner     290\n",
      "Name: traj, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### 어떤 trajectories가 있나 확인 (revisit_intention == 1인 경우)\n",
    "print('Top 10 trajectories with revisit intention in 3 months\\n', trajs_combined.loc[trajs_combined['revisit_intention'] == 1]['traj'].value_counts().head(10))\n",
    "print(' ')\n",
    "### 어떤 trajectories가 있나 확인 (revisit_intention == 0인 경우)\n",
    "print('Top 10 trajectories with no revisit intention in 3 months\\n', trajs_combined.loc[trajs_combined['revisit_intention'] == 0]['traj'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    16036\n",
      "2.0     1932\n",
      "3.0      914\n",
      "Name: new_visit_count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bde3e80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAcYhEAHGIRABxjE/wH5udw70otYTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f704e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 재방문 횟수별 사람 수\n",
    "customer_revisit_count = trajs_combined.groupby(['device_id'])['new_visit_count'].max().value_counts().sort_index()\n",
    "print (customer_revisit_count)\n",
    "\n",
    "%matplotlib inline \n",
    "customer_revisit_count.plot(kind='bar', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 알고 싶은 방문객의 방문 횟수 범위는 3번 이하였다. 원본 데이터의 방문 횟수는 아래와 같다\n",
    "![](2016-09-18_10.07.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data preprocessing\n",
    "라벨 비율 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Revisit intention 비율을 50대 50으로 맞춤 (sampling)\n",
    "# trajs_combined = trajs_combined.loc[trajs_combined['prob_deny']==0]\n",
    "def balancing(trajs_combined):\n",
    "    trajs_1 = trajs_combined.loc[trajs_combined['revisit_intention']==1]\n",
    "    trajs_0 = trajs_combined.loc[trajs_combined['revisit_intention']==0]\n",
    "\n",
    "    new_trajs_0 = trajs_0.iloc[np.random.permutation(len(trajs_0))][:trajs_1.shape[0]]  ## trajs_1의 크기에 맞게 trajs_0을 랜덤 샘플링.\n",
    "\n",
    "    # 1:1 비율의 dataframe 만들기\n",
    "    trajs_combined_balanced = pd.concat([trajs_1, new_trajs_0])\n",
    "    trajs_combined_balanced = trajs_combined_balanced.sample(frac=1)  ## reshuffle after concatenation\n",
    "\n",
    "#     print(trajs_1.shape)\n",
    "#     print(trajs_0.shape)\n",
    "#     print(trajs_combined_balanced.shape) ## 이용할 데이터\n",
    "    return trajs_combined_balanced\n",
    "\n",
    "trajs_combined_balanced = balancing(trajs_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device_id</th>\n",
       "      <th>traj</th>\n",
       "      <th>new_visit_count</th>\n",
       "      <th>num_logs</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>num_sp_100</th>\n",
       "      <th>prob_dwell_100</th>\n",
       "      <th>time_sp_100</th>\n",
       "      <th>std_sp_100</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>revisit_intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16760_0d4ddf93b8bc9fc11e727865e02351ef</th>\n",
       "      <td>16760.0</td>\n",
       "      <td>0d4ddf93b8bc9fc11e727865e02351ef</td>\n",
       "      <td>out,in,1f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16811_532e1ee8aff9231db8feb9e2cc0f7a72</th>\n",
       "      <td>16811.0</td>\n",
       "      <td>532e1ee8aff9231db8feb9e2cc0f7a72</td>\n",
       "      <td>out,in,1f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1454</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16716_ae2e3efee17983808b5ccc6f9cff2b73</th>\n",
       "      <td>16716.0</td>\n",
       "      <td>ae2e3efee17983808b5ccc6f9cff2b73</td>\n",
       "      <td>out,in,2f-right,2f,1f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16791_b49a8debc8537eb5bfe80306f7cc9b18</th>\n",
       "      <td>16791.0</td>\n",
       "      <td>b49a8debc8537eb5bfe80306f7cc9b18</td>\n",
       "      <td>out,in</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16677_8f7cf76e54bd832010f91b7b78d17ba2</th>\n",
       "      <td>16677.0</td>\n",
       "      <td>8f7cf76e54bd832010f91b7b78d17ba2</td>\n",
       "      <td>out,in,1f,1f-right,1f-inner,1f-left,2f,1f,1f-r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8793</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6615.0</td>\n",
       "      <td>709.224048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           date  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef  16760.0   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72  16811.0   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73  16716.0   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18  16791.0   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2  16677.0   \n",
       "\n",
       "                                                               device_id  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef  0d4ddf93b8bc9fc11e727865e02351ef   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72  532e1ee8aff9231db8feb9e2cc0f7a72   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73  ae2e3efee17983808b5ccc6f9cff2b73   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18  b49a8debc8537eb5bfe80306f7cc9b18   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2  8f7cf76e54bd832010f91b7b78d17ba2   \n",
       "\n",
       "                                                                                     traj  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef                                          out,in,1f   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72                                          out,in,1f   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73                              out,in,2f-right,2f,1f   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18                                             out,in   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2  out,in,1f,1f-right,1f-inner,1f-left,2f,1f,1f-r...   \n",
       "\n",
       "                                        new_visit_count  num_logs  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef              1.0         3   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72              1.0         3   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73              2.0         5   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18              1.0         2   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2              1.0        11   \n",
       "\n",
       "                                        total_dwell_time  num_sp_100  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef              4214         2.0   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72              1454         2.0   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73                68         0.0   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18               255         0.0   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2              8793         9.0   \n",
       "\n",
       "                                        prob_dwell_100  time_sp_100  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef             1.0       1328.0   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72             1.0        512.0   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73             0.0          0.0   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18             0.0          0.0   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2             0.9       6615.0   \n",
       "\n",
       "                                        std_sp_100  Fri  Mon  Sat  Sun  Thu  \\\n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef    0.000000  0.0  0.0  1.0  0.0  0.0   \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72    0.000000  0.0  1.0  0.0  0.0  0.0   \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73    0.000000  0.0  0.0  0.0  0.0  1.0   \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18    0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2  709.224048  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "                                        Tue  Wed  revisit_intention  \n",
       "16760_0d4ddf93b8bc9fc11e727865e02351ef  0.0  0.0                0.0  \n",
       "16811_532e1ee8aff9231db8feb9e2cc0f7a72  0.0  0.0                0.0  \n",
       "16716_ae2e3efee17983808b5ccc6f9cff2b73  0.0  0.0                1.0  \n",
       "16791_b49a8debc8537eb5bfe80306f7cc9b18  1.0  0.0                0.0  \n",
       "16677_8f7cf76e54bd832010f91b7b78d17ba2  0.0  0.0                1.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learning = trajs_combined_balanced\n",
    "df_learning = df_learning.fillna(0)\n",
    "df_learning = df_learning.reindex(np.random.permutation(df_learning.index))\n",
    "df_learning.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DataFame to nparray, divide features and labels\n",
    "data = np.asarray(df_learning)\n",
    "X_small, y = data[:, 3:-1], data[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some trajectory features (Uni-gram, Bi-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[1 0 0 ..., 1 1 0]\n",
      " [1 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 2 1 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 1 0]\n",
      " [0 0 0 ..., 2 1 1]\n",
      " [1 0 0 ..., 1 1 0]]\n",
      "['date', 'device_id', 'traj', 'new_visit_count', 'num_logs', 'total_dwell_time', 'num_sp_100', 'prob_dwell_100', 'time_sp_100', 'std_sp_100', 'Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed', '1f', '1f 1f', '1f 1f-inner', '1f 1f-left', '1f 1f-right', '1f 2f', '1f 2f-inner', '1f 2f-left', '1f 2f-right', '1f 3f', '1f in', '1f out', '1f-inner', '1f-inner 1f', '1f-inner 1f-inner', '1f-inner 1f-left', '1f-inner 1f-right', '1f-inner 2f', '1f-inner 2f-inner', '1f-inner 2f-left', '1f-inner 2f-right', '1f-inner 3f', '1f-inner in', '1f-inner out', '1f-left', '1f-left 1f', '1f-left 1f-inner', '1f-left 1f-left', '1f-left 1f-right', '1f-left 2f', '1f-left 2f-inner', '1f-left 2f-left', '1f-left 2f-right', '1f-left 3f', '1f-left in', '1f-left out', '1f-right', '1f-right 1f', '1f-right 1f-inner', '1f-right 1f-left', '1f-right 1f-right', '1f-right 2f', '1f-right 2f-inner', '1f-right 2f-left', '1f-right 2f-right', '1f-right 3f', '1f-right in', '1f-right out', '2f', '2f 1f', '2f 1f-inner', '2f 1f-left', '2f 1f-right', '2f 2f', '2f 2f-inner', '2f 2f-left', '2f 2f-right', '2f 3f', '2f in', '2f out', '2f-inner', '2f-inner 1f', '2f-inner 1f-inner', '2f-inner 1f-left', '2f-inner 1f-right', '2f-inner 2f', '2f-inner 2f-inner', '2f-inner 2f-left', '2f-inner 2f-right', '2f-inner 3f', '2f-inner in', '2f-inner out', '2f-left', '2f-left 1f', '2f-left 1f-inner', '2f-left 1f-left', '2f-left 1f-right', '2f-left 2f', '2f-left 2f-inner', '2f-left 2f-left', '2f-left 2f-right', '2f-left 3f', '2f-left in', '2f-left out', '2f-right', '2f-right 1f', '2f-right 1f-inner', '2f-right 1f-left', '2f-right 1f-right', '2f-right 2f', '2f-right 2f-inner', '2f-right 2f-left', '2f-right 2f-right', '2f-right 3f', '2f-right in', '2f-right out', '3f', '3f 1f', '3f 1f-inner', '3f 1f-left', '3f 1f-right', '3f 2f', '3f 2f-inner', '3f 2f-left', '3f 2f-right', '3f 3f', '3f in', '3f out', 'in', 'in 1f', 'in 1f-inner', 'in 1f-left', 'in 1f-right', 'in 2f', 'in 2f-inner', 'in 2f-left', 'in 2f-right', 'in 3f', 'in in', 'in out', 'out', 'out in', 'out out']\n",
      "(5378, 137)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bigram_vectorizer = CountVectorizer(min_df=1, token_pattern='\\w+\\-*\\w+', ngram_range=(1, 2))\n",
    "\n",
    "### Test with toy example\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "print(analyze('Bi-grams are cool!') == (['bi-grams', 'are', 'cool', 'bi-grams are', 'are cool']))\n",
    "\n",
    "### Trajecory를 이용하여 bi-gram 생성 후 각 moving pattern별로 count\n",
    "corpus = trajs_combined_balanced['traj']\n",
    "corpvec2 = bigram_vectorizer.fit_transform(corpus)\n",
    "print(corpvec2.toarray())\n",
    "corpvec2\n",
    "\n",
    "X = np.concatenate((X_small, corpvec2.toarray()), axis=1)\n",
    "newcolumns = df_learning.columns.tolist()[:-1]+bigram_vectorizer.get_feature_names()\n",
    "print(newcolumns)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analysis with sklearn classifiers\n",
    "\n",
    "### Decision tree\n",
    "* Decision tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "* Cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html\n",
    "* Adjusting different scoring parameters: http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features [[1.0 5 9403 4.0 1.0 5744.0 996.0003346719652 0.0 0.0 0.0 0.0 0.0 0.0 1.0]\n",
      " [1.0 6 344 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0]\n",
      " [1.0 4 4685 2.0 1.0 906.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0]\n",
      " [1.0 6 3604 4.0 0.8 2466.0 125.12793453102309 0.0 0.0 1.0 0.0 0.0 0.0 0.0]]\n",
      "Labels [1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features\", X_small[1:5])\n",
    "print(\"Labels\", y[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "  * accuracy 0.613\n",
      "  * precision 0.624\n",
      "  * recall 0.576\n",
      "  * f1 0.598\n",
      "  * roc_auc 0.647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "print('Decision tree')\n",
    "for criteria in scoring:\n",
    "    score = cross_val_score(clf, X, y, cv=10, scoring=criteria)  ## accuracy\n",
    "    avgscore = score.sum()/len(score)\n",
    "    print('  *', criteria, round(avgscore,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1: new_visit_count (0.530494)\n",
      "2. feature 6: time_sp_100 (0.303475)\n",
      "3. feature 3: total_dwell_time (0.052346)\n",
      "4. feature 11: Sun (0.029586)\n",
      "5. feature 8: Fri (0.016562)\n",
      "6. feature 137: out out (0.013155)\n",
      "7. feature 2: num_logs (0.011446)\n",
      "8. feature 128: in 2f (0.011224)\n",
      "9. feature 123: in (0.010288)\n",
      "10. feature 19: 1f 1f-right (0.009431)\n",
      "11. feature 5: prob_dwell_100 (0.006834)\n",
      "12. feature 62: 1f-right out (0.005160)\n",
      "13. feature 42: 1f-left 1f-left (0.000000)\n",
      "14. feature 47: 1f-left 2f-right (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEKCAYAAADkYmWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11765e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "clf.fit(X,y)\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "\n",
    "numShow = X_small.shape[1]\n",
    "for f in range(numShow):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f]+1, newcolumns[indices[f]+3], importances[indices[f]]))\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices+1)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "plt.bar(range(numShow), importances[indices][:numShow], color=\"r\", align=\"center\")  # Just plot top 15 features\n",
    "plt.xticks(range(numShow), indices+1)\n",
    "plt.xlim([-1, numShow])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_top10 = X[:, [0,5,2,10,7,136,1,127,122,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5378, 10)\n",
      "Decision tree\n",
      "  * accuracy 0.592\n",
      "  * precision 0.604\n",
      "  * recall 0.537\n",
      "  * f1 0.568\n",
      "  * roc_auc 0.613\n"
     ]
    }
   ],
   "source": [
    "# Top feature 10개로만 진행\n",
    "print(X_top10.shape)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "print('Decision tree')\n",
    "for criteria in scoring:\n",
    "    score = cross_val_score(clf, X_top10, y, cv=10, scoring=criteria)  ## accuracy\n",
    "    avgscore = score.sum()/len(score)\n",
    "    print('  *', criteria, round(avgscore,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * accuracy 0.577\n",
      "  * precision 0.596\n",
      "  * recall 0.475\n",
      "  * f1 0.528\n",
      "  * roc_auc 0.602\n"
     ]
    }
   ],
   "source": [
    "# Basic feature만 가지고 테스트\n",
    "X_first7 = X[:, 0:7]\n",
    "for criteria in scoring:\n",
    "    score = cross_val_score(clf, X_first7, y, cv=10, scoring=criteria)  ## accuracy\n",
    "    avgscore = score.sum()/len(score)\n",
    "    print('  *', criteria, round(avgscore,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * accuracy 0.569\n",
      "  * precision 0.592\n",
      "  * recall 0.447\n",
      "  * f1 0.509\n",
      "  * roc_auc 0.583\n"
     ]
    }
   ],
   "source": [
    "# Basic feature - history(지금까지 방문 횟수) 제거 \n",
    "X_2_7 = X[:, 1:7]\n",
    "for criteria in scoring:\n",
    "    score = cross_val_score(clf, X_2_7, y, cv=10, scoring=criteria)  ## accuracy\n",
    "    avgscore = score.sum()/len(score)\n",
    "    print('  *', criteria, round(avgscore,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\"3 Nearest Neighbors\",  \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"Logistic Regression\"\n",
    "        ]  ## \"Linear SVM\", \"RBF SVM\", \"Linear Discriminant Analysis\", \"Quadratic Discriminant Analysis\"\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),  ## very slow (can't wait)  \n",
    "#     SVC(gamma=2, C=1), ## very slow (can't wait)\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "#     LinearDiscriminantAnalysis(),\n",
    "    LogisticRegression(penalty='l2', class_weight='balanced', solver='liblinear')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring criteria: accuracy\n",
      "  * 3 Nearest Neighbors 0.518\n",
      "  * Decision Tree 0.617\n",
      "  * Random Forest 0.595\n",
      "  * AdaBoost 0.622\n",
      "  * Naive Bayes 0.567\n",
      "  * Logistic Regression 0.583\n",
      "Scoring criteria: precision\n",
      "  * 3 Nearest Neighbors 0.519\n",
      "  * Decision Tree 0.626\n",
      "  * Random Forest 0.618\n",
      "  * AdaBoost 0.643\n",
      "  * Naive Bayes 0.64\n",
      "  * Logistic Regression 0.596\n",
      "Scoring criteria: recall\n",
      "  * 3 Nearest Neighbors 0.512\n",
      "  * Decision Tree 0.586\n",
      "  * Random Forest 0.519\n",
      "  * AdaBoost 0.55\n",
      "  * Naive Bayes 0.308\n",
      "  * Logistic Regression 0.514\n",
      "Scoring criteria: f1\n",
      "  * 3 Nearest Neighbors 0.515\n",
      "  * Decision Tree 0.604\n",
      "  * Random Forest 0.583\n",
      "  * AdaBoost 0.592\n",
      "  * Naive Bayes 0.416\n",
      "  * Logistic Regression 0.552\n",
      "Scoring criteria: roc_auc\n",
      "  * 3 Nearest Neighbors 0.52\n",
      "  * Decision Tree 0.65\n",
      "  * Random Forest 0.636\n",
      "  * AdaBoost 0.659\n",
      "  * Naive Bayes 0.608\n",
      "  * Logistic Regression 0.608\n"
     ]
    }
   ],
   "source": [
    "for criteria in scoring:\n",
    "    print('Scoring criteria:', criteria)\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        score = cross_val_score(clf, X_small, y, cv=10, scoring=criteria)\n",
    "        avgscore = score.sum()/len(score)\n",
    "        print('  *', name, round(avgscore,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling마다 결과가 변하므로 반복실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(min_df=1, token_pattern='\\w+\\-*\\w+', ngram_range=(1, 2))\n",
    "results_dict = dict()\n",
    "\n",
    "for i in range(100):\n",
    "    trajs_combined_balanced = balancing(trajs_combined)\n",
    "    df_learning = trajs_combined_balanced\n",
    "    df_learning = df_learning.fillna(0)\n",
    "    df_learning = df_learning.reindex(np.random.permutation(df_learning.index))\n",
    "    df_learning.tail(5)\n",
    "    data = np.asarray(df_learning)\n",
    "    X_small, y = data[:, 3:-1], data[:, -1].astype(int)\n",
    "\n",
    "    corpus = trajs_combined_balanced['traj']\n",
    "    corpvec2 = bigram_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    X = np.concatenate((X_small, corpvec2.toarray()), axis=1)\n",
    "    newcolumns = df_learning.columns.tolist()[:-1]+bigram_vectorizer.get_feature_names()\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    \n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        results_dict.setdefault(name, dict())\n",
    "        for criteria in scoring:\n",
    "            score = cross_val_score(clf, X_small, y, cv=10, scoring=criteria)\n",
    "            avgscore = score.sum()/len(score)\n",
    "#             print('  *', name, criteria, round(avgscore,3))\n",
    "            results_dict[name].setdefault(criteria, []).append(avgscore)\n",
    "    \n",
    "    \n",
    "#     for criteria in scoring:\n",
    "#         score = cross_val_score(clf, X, y, cv=10, scoring=criteria)  ## accuracy\n",
    "#         avgscore = score.sum()/len(score)\n",
    "#         results_dict.setdefault(criteria, []).append(avgscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.53645896909504531,\n",
       "  0.53235657215779841,\n",
       "  0.52750027742329242,\n",
       "  0.52416495588969647,\n",
       "  0.52827220773456152,\n",
       "  0.52975572879098931,\n",
       "  0.54203170948232815,\n",
       "  0.51803182045164509,\n",
       "  0.51970607002163904,\n",
       "  0.52975780946568274,\n",
       "  0.52212381401542474,\n",
       "  0.5275217777284581,\n",
       "  0.52883676413471681,\n",
       "  0.5052044609665427,\n",
       "  0.52232147811130214,\n",
       "  0.53069550019419631,\n",
       "  0.51262761471453144,\n",
       "  0.52527950396715306,\n",
       "  0.52286661488098551,\n",
       "  0.52231384897075961,\n",
       "  0.52286592132275422,\n",
       "  0.52713338511901464,\n",
       "  0.5310561504743937,\n",
       "  0.52863563224768362,\n",
       "  0.52268975753204239,\n",
       "  0.52100995949619933,\n",
       "  0.51040476058369866,\n",
       "  0.52621580757920428,\n",
       "  0.52882428008655613,\n",
       "  0.52639474560284083,\n",
       "  0.51859568329356931,\n",
       "  0.53718997947067637,\n",
       "  0.52715072407479335,\n",
       "  0.51989610497697381,\n",
       "  0.52436123286911174,\n",
       "  0.53309451811574093,\n",
       "  0.5126435665538478,\n",
       "  0.52639682627753426,\n",
       "  0.51897020473838973,\n",
       "  0.53105198912500684,\n",
       "  0.52677828330466625,\n",
       "  0.52101065305443051,\n",
       "  0.53849040115408076,\n",
       "  0.52846016201520274,\n",
       "  0.5232480719081174,\n",
       "  0.5327290129279254,\n",
       "  0.51672654386062256,\n",
       "  0.53514536980524885,\n",
       "  0.51245630583143753,\n",
       "  0.52342284858236698,\n",
       "  0.52379667646895633,\n",
       "  0.51321159074515899,\n",
       "  0.52751414858791545,\n",
       "  0.52808355989568878,\n",
       "  0.52882705431948063,\n",
       "  0.52509224324474291,\n",
       "  0.5379341674526994,\n",
       "  0.51840842257115916,\n",
       "  0.53234408810963763,\n",
       "  0.53141749431282248,\n",
       "  0.52918354325029127,\n",
       "  0.51412986184320031,\n",
       "  0.53328594018753828,\n",
       "  0.52807593075514625,\n",
       "  0.50948232813627037,\n",
       "  0.52937912667147535,\n",
       "  0.53328108527992024,\n",
       "  0.51041308328247248,\n",
       "  0.52324391055873054,\n",
       "  0.51152832491816014,\n",
       "  0.52326471730566504,\n",
       "  0.52174651833767971,\n",
       "  0.52119791377684077,\n",
       "  0.53161169061754421,\n",
       "  0.52082963435610052,\n",
       "  0.53050269100593694,\n",
       "  0.52286938911391001,\n",
       "  0.52919255950729616,\n",
       "  0.52937982022970653,\n",
       "  0.53010944348887545,\n",
       "  0.51225864173556013,\n",
       "  0.50743633135438049,\n",
       "  0.52118751040337352,\n",
       "  0.5362495145092383,\n",
       "  0.52825417522055151,\n",
       "  0.52064029295899683,\n",
       "  0.51450022193863387,\n",
       "  0.52325153969927318,\n",
       "  0.51636658713865613,\n",
       "  0.53513565999001278,\n",
       "  0.52714933695833099,\n",
       "  0.52175553459468449,\n",
       "  0.52529129445708256,\n",
       "  0.5204523386783555,\n",
       "  0.54221411529712038,\n",
       "  0.51263801808799869,\n",
       "  0.52008197858292182,\n",
       "  0.52416287521500304,\n",
       "  0.51860331243411195,\n",
       "  0.51764342784220152],\n",
       " 'f1': [0.53051762419987569,\n",
       "  0.52785007714808763,\n",
       "  0.52432697714088261,\n",
       "  0.5180047495220319,\n",
       "  0.5245368588332433,\n",
       "  0.5242597172725495,\n",
       "  0.53755315188336372,\n",
       "  0.51079651488921662,\n",
       "  0.50951414739257361,\n",
       "  0.52688221050084727,\n",
       "  0.52052384947521446,\n",
       "  0.5230967029319229,\n",
       "  0.52581366240256178,\n",
       "  0.50448461097590225,\n",
       "  0.51787580542226186,\n",
       "  0.52806596472554224,\n",
       "  0.50794113183708345,\n",
       "  0.52426357500090626,\n",
       "  0.51972485006024716,\n",
       "  0.51929408826572698,\n",
       "  0.51822487125223793,\n",
       "  0.52815420847205052,\n",
       "  0.52763622058764015,\n",
       "  0.52578440033075102,\n",
       "  0.52210346660531637,\n",
       "  0.52027067223439472,\n",
       "  0.5091079098623762,\n",
       "  0.52354954471324244,\n",
       "  0.52699957527121666,\n",
       "  0.5206539219894768,\n",
       "  0.51450284397512525,\n",
       "  0.53197562486304928,\n",
       "  0.51746027854566656,\n",
       "  0.51822626505970848,\n",
       "  0.52009406589743024,\n",
       "  0.52985728662999831,\n",
       "  0.50944089451597341,\n",
       "  0.52591078566370897,\n",
       "  0.51457982981594264,\n",
       "  0.52724286710873136,\n",
       "  0.52506497542229635,\n",
       "  0.52005043722743072,\n",
       "  0.5326382608492346,\n",
       "  0.520333645461314,\n",
       "  0.52005367104671762,\n",
       "  0.5264046904021743,\n",
       "  0.51301010983557593,\n",
       "  0.52909748605769169,\n",
       "  0.50958436107807237,\n",
       "  0.51915229221877646,\n",
       "  0.52129010677287091,\n",
       "  0.51260905169038584,\n",
       "  0.5245399694050481,\n",
       "  0.52420012712878683,\n",
       "  0.52522429149900896,\n",
       "  0.52816897132143736,\n",
       "  0.53514421732689421,\n",
       "  0.51193201573444291,\n",
       "  0.52884551037848437,\n",
       "  0.5322268765138265,\n",
       "  0.52859064431310487,\n",
       "  0.5088828689350906,\n",
       "  0.53150862693360224,\n",
       "  0.5226953839178059,\n",
       "  0.50393985050435153,\n",
       "  0.53030337198377953,\n",
       "  0.53350723433652036,\n",
       "  0.50713960168245198,\n",
       "  0.51976195481881149,\n",
       "  0.51044247587330549,\n",
       "  0.52080208494026159,\n",
       "  0.51488753445851898,\n",
       "  0.5191294647788911,\n",
       "  0.52896004457899393,\n",
       "  0.51819666862935854,\n",
       "  0.53097795689516047,\n",
       "  0.51732742834008794,\n",
       "  0.52694839345664435,\n",
       "  0.52742105858553456,\n",
       "  0.52767881735223521,\n",
       "  0.5092505547235453,\n",
       "  0.50695408205611536,\n",
       "  0.51674996402270412,\n",
       "  0.53639714844440123,\n",
       "  0.52553313772545329,\n",
       "  0.51685862730461074,\n",
       "  0.51183358156124081,\n",
       "  0.51550826903482039,\n",
       "  0.51591166134050348,\n",
       "  0.53132442721760842,\n",
       "  0.52299662167759353,\n",
       "  0.51595670346666433,\n",
       "  0.52023950972615418,\n",
       "  0.51414778633207314,\n",
       "  0.5367823687983676,\n",
       "  0.50843463422843538,\n",
       "  0.51369436770603538,\n",
       "  0.52191540897324418,\n",
       "  0.51253271919292565,\n",
       "  0.51361488043275527],\n",
       " 'precision': [0.53750808447837883,\n",
       "  0.5328895326100751,\n",
       "  0.52782082822752252,\n",
       "  0.52481422411559431,\n",
       "  0.52927068007996469,\n",
       "  0.53042357575094745,\n",
       "  0.5432799671832077,\n",
       "  0.51827538098990233,\n",
       "  0.5207203074455331,\n",
       "  0.53009195653789498,\n",
       "  0.52250986052982495,\n",
       "  0.52778219242208624,\n",
       "  0.52940158957151573,\n",
       "  0.5051423764353028,\n",
       "  0.52241864692740803,\n",
       "  0.53156934240532627,\n",
       "  0.51272090028817763,\n",
       "  0.5256194907645817,\n",
       "  0.52370479711408402,\n",
       "  0.52286581968989632,\n",
       "  0.52379265012419984,\n",
       "  0.52703685139527034,\n",
       "  0.53135602454548692,\n",
       "  0.5291840079782808,\n",
       "  0.52311370653937916,\n",
       "  0.52097443592334047,\n",
       "  0.51066564667883707,\n",
       "  0.52683869318772136,\n",
       "  0.52944184009016537,\n",
       "  0.52793305904244503,\n",
       "  0.51900234741367546,\n",
       "  0.53807573339972448,\n",
       "  0.52813362661979768,\n",
       "  0.51970715590689964,\n",
       "  0.52498904148480485,\n",
       "  0.53383265130622282,\n",
       "  0.51277233524311749,\n",
       "  0.52646731327473473,\n",
       "  0.51989892481939581,\n",
       "  0.53151566926564664,\n",
       "  0.52717687264863211,\n",
       "  0.52119954729768692,\n",
       "  0.53950356744453054,\n",
       "  0.52931102174490063,\n",
       "  0.52301592805221397,\n",
       "  0.53362767797443955,\n",
       "  0.51707897533660097,\n",
       "  0.53595403296425692,\n",
       "  0.5123014103649195,\n",
       "  0.52376075511872389,\n",
       "  0.52405390174541178,\n",
       "  0.51364752979430883,\n",
       "  0.52786359970573438,\n",
       "  0.5287016362018464,\n",
       "  0.52934208582333719,\n",
       "  0.52505683540379022,\n",
       "  0.53811415636414961,\n",
       "  0.51906239454885861,\n",
       "  0.53282376244832697,\n",
       "  0.53187230148993736,\n",
       "  0.52959600212161062,\n",
       "  0.51408048715832277,\n",
       "  0.53351640115170251,\n",
       "  0.52847833762823238,\n",
       "  0.50996403435205173,\n",
       "  0.52899801235087884,\n",
       "  0.53300664774726347,\n",
       "  0.51071586926919132,\n",
       "  0.52325689078955706,\n",
       "  0.51125160809752968,\n",
       "  0.52369259048815775,\n",
       "  0.52210116892513159,\n",
       "  0.52124919033110084,\n",
       "  0.53217604302075094,\n",
       "  0.52080750757216976,\n",
       "  0.53055418034354751,\n",
       "  0.52334092906389951,\n",
       "  0.52936715967530068,\n",
       "  0.52951334371381742,\n",
       "  0.53112061096079133,\n",
       "  0.51232806802390185,\n",
       "  0.50725006042428444,\n",
       "  0.52127763685377004,\n",
       "  0.53674910768454476,\n",
       "  0.52877382023344222,\n",
       "  0.52081351695184008,\n",
       "  0.51449263360009445,\n",
       "  0.52405864557087845,\n",
       "  0.51677353284788352,\n",
       "  0.53525838049190999,\n",
       "  0.52783258547369161,\n",
       "  0.52230969188613419,\n",
       "  0.52607168995115283,\n",
       "  0.520594589828837,\n",
       "  0.5431070833554088,\n",
       "  0.51279577546854216,\n",
       "  0.52086279149033421,\n",
       "  0.52444696267017021,\n",
       "  0.51897765811678609,\n",
       "  0.51776276719670511],\n",
       " 'recall': [0.52400127614714531,\n",
       "  0.52360456083892815,\n",
       "  0.52136991621816564,\n",
       "  0.51169894024302287,\n",
       "  0.52027964267879923,\n",
       "  0.51840564833823444,\n",
       "  0.53253897797259053,\n",
       "  0.50427093158741598,\n",
       "  0.49907618043610952,\n",
       "  0.52436192642734281,\n",
       "  0.51914775564556404,\n",
       "  0.5187912667147534,\n",
       "  0.52250457748432555,\n",
       "  0.50427509293680295,\n",
       "  0.51432197747322861,\n",
       "  0.52548410364534204,\n",
       "  0.50388253897797264,\n",
       "  0.52361981912001332,\n",
       "  0.5165538478610664,\n",
       "  0.51618348776563272,\n",
       "  0.51394468179548347,\n",
       "  0.52955529046218719,\n",
       "  0.52434805526271988,\n",
       "  0.52287077623037237,\n",
       "  0.52175276036175999,\n",
       "  0.51989541141874274,\n",
       "  0.50798146812406375,\n",
       "  0.52101897575320422,\n",
       "  0.52511513066637072,\n",
       "  0.51430810630860557,\n",
       "  0.51023830660822278,\n",
       "  0.52659240969871823,\n",
       "  0.50763330189202693,\n",
       "  0.51730566498363195,\n",
       "  0.51618903623148193,\n",
       "  0.52621511402097321,\n",
       "  0.50651528602341445,\n",
       "  0.52584475392553964,\n",
       "  0.5105836986073351,\n",
       "  0.52323558785995661,\n",
       "  0.52361288353770186,\n",
       "  0.51951256727514838,\n",
       "  0.52622343671974692,\n",
       "  0.51209149420185318,\n",
       "  0.51805470787327301,\n",
       "  0.5199023470010542,\n",
       "  0.50982772013538247,\n",
       "  0.52325223325750425,\n",
       "  0.50762497919325311,\n",
       "  0.51468262775342621,\n",
       "  0.51878016978305497,\n",
       "  0.51208455861954172,\n",
       "  0.52175692171114696,\n",
       "  0.52063613160961009,\n",
       "  0.52139488431448711,\n",
       "  0.5318010320146479,\n",
       "  0.53254452643843975,\n",
       "  0.5053820118737169,\n",
       "  0.52508877545358712,\n",
       "  0.53328108527992002,\n",
       "  0.5280710758475281,\n",
       "  0.50427648005326531,\n",
       "  0.529945070188093,\n",
       "  0.51729456805193352,\n",
       "  0.49832297619708149,\n",
       "  0.5317982577817234,\n",
       "  0.53438245575098486,\n",
       "  0.50390889419075624,\n",
       "  0.51654552516229268,\n",
       "  0.51023553237529817,\n",
       "  0.51841951950285747,\n",
       "  0.50835044110303496,\n",
       "  0.51729456805193352,\n",
       "  0.52622204960328467,\n",
       "  0.5161723908339344,\n",
       "  0.53179548354879869,\n",
       "  0.51209288131831543,\n",
       "  0.52473367363923873,\n",
       "  0.52547994229595507,\n",
       "  0.52472812517338963,\n",
       "  0.50649170504355545,\n",
       "  0.5072351994673473,\n",
       "  0.51281973034455974,\n",
       "  0.53663097153637007,\n",
       "  0.52286800199744776,\n",
       "  0.51358680574821058,\n",
       "  0.50947677967042115,\n",
       "  0.50762775342617761,\n",
       "  0.51543583199245402,\n",
       "  0.52843311324418807,\n",
       "  0.51878433113244182,\n",
       "  0.51021888697775064,\n",
       "  0.51544831604061481,\n",
       "  0.50835460245242192,\n",
       "  0.53105892470731841,\n",
       "  0.50426260888864227,\n",
       "  0.50724490928258337,\n",
       "  0.51990650835044117,\n",
       "  0.5072587804472064,\n",
       "  0.50983188148476954],\n",
       " 'roc_auc': [0.54010269234233432,\n",
       "  0.53553427273201426,\n",
       "  0.53169803737628296,\n",
       "  0.53299101839358443,\n",
       "  0.54207279627523108,\n",
       "  0.5359031720278794,\n",
       "  0.54629989646783761,\n",
       "  0.52460048377170099,\n",
       "  0.52789421858516927,\n",
       "  0.53909856678375367,\n",
       "  0.5339110329691823,\n",
       "  0.54006067955125636,\n",
       "  0.53416973313326177,\n",
       "  0.51115795322045121,\n",
       "  0.52846656684633442,\n",
       "  0.53443907970287907,\n",
       "  0.51991518774702516,\n",
       "  0.53636276417357109,\n",
       "  0.52794624356255349,\n",
       "  0.53170894060001106,\n",
       "  0.52969495874775818,\n",
       "  0.5249596370986398,\n",
       "  0.53327246540512463,\n",
       "  0.53568351403949488,\n",
       "  0.52597258389787238,\n",
       "  0.53294418022970214,\n",
       "  0.51601146870015224,\n",
       "  0.5282629125034457,\n",
       "  0.54104548093357285,\n",
       "  0.52969032729457388,\n",
       "  0.5260958172815694,\n",
       "  0.54135202548472883,\n",
       "  0.53396728902505042,\n",
       "  0.52284556129227799,\n",
       "  0.53197493941295726,\n",
       "  0.5380353837874412,\n",
       "  0.52274237406191615,\n",
       "  0.53137455796716659,\n",
       "  0.52408123098541015,\n",
       "  0.53927969912858231,\n",
       "  0.53799914023253781,\n",
       "  0.52636394592976166,\n",
       "  0.54741364640303802,\n",
       "  0.54143178521043644,\n",
       "  0.53451449472284496,\n",
       "  0.5440679899840325,\n",
       "  0.52783665541658753,\n",
       "  0.54008595133665127,\n",
       "  0.51832402740939665,\n",
       "  0.5313170645757842,\n",
       "  0.52806068915593918,\n",
       "  0.52240015166778953,\n",
       "  0.53033510587596822,\n",
       "  0.53641954972033878,\n",
       "  0.53606993968808692,\n",
       "  0.53266945312899239,\n",
       "  0.54325960670929851,\n",
       "  0.52659731761507311,\n",
       "  0.54192219252776896,\n",
       "  0.54249814561392795,\n",
       "  0.53445009293657209,\n",
       "  0.51703647738250225,\n",
       "  0.54029506379964554,\n",
       "  0.5357171718936361,\n",
       "  0.51751771974899419,\n",
       "  0.5372140191156054,\n",
       "  0.53911921618805836,\n",
       "  0.52022011386736922,\n",
       "  0.52697919963566375,\n",
       "  0.51307585520759469,\n",
       "  0.53008832631854519,\n",
       "  0.51862004073116685,\n",
       "  0.52915432052459899,\n",
       "  0.53263161961983951,\n",
       "  0.53083380735778896,\n",
       "  0.53255725982969315,\n",
       "  0.53353335495510001,\n",
       "  0.53578596377498289,\n",
       "  0.53384749378225016,\n",
       "  0.53968354408303831,\n",
       "  0.52149525353882953,\n",
       "  0.5163340168390812,\n",
       "  0.52957349489382444,\n",
       "  0.54104108068891343,\n",
       "  0.54257459248599438,\n",
       "  0.52690607326550443,\n",
       "  0.52576739000232631,\n",
       "  0.53221996343838684,\n",
       "  0.51990684806813869,\n",
       "  0.54049357922930474,\n",
       "  0.53194557987469737,\n",
       "  0.52583088785014021,\n",
       "  0.53172094682876503,\n",
       "  0.53126911825992962,\n",
       "  0.5476173692339843,\n",
       "  0.52230400738407734,\n",
       "  0.52635386021427633,\n",
       "  0.53515311659440168,\n",
       "  0.52417992354629361,\n",
       "  0.52623519520240469]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['3 Nearest Neighbors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preliminary_results_160918_sample.pickle', 'wb') as handle:\n",
    "  pickle.dump(results_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost로 테스트\n",
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting(also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment(Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\n",
    "* https://xgboost.readthedocs.io/en/latest/\n",
    "* https://xgboost.readthedocs.io/en/latest/model.html\n",
    "* https://github.com/dmlc/xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "import re\n",
    "\n",
    "trajs_combined = pd.read_pickle(\"../data/786/786_trajs_combined.p\")\n",
    "random.seed(2016)\n",
    "datadir = \"../data/786/786_trajs_combined.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, test, random_state=0):\n",
    "    start_time = time.time()\n",
    "    objective = \"reg:logistic\"\n",
    "    booster = \"gbtree\"\n",
    "    eval_metric = [\"auc\", \"logloss\", \"error\"]\n",
    "    eta = 0.1\n",
    "    max_depth = 3\n",
    "    subsample = 0.7\n",
    "    colsample_bytree = 0.7\n",
    "    silent = 1\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": objective,\n",
    "#         \"num_class\": 2,\n",
    "        \"booster\" : booster,\n",
    "        \"eval_metric\": eval_metric,\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": silent,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 100\n",
    "    test_size = 0.1\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', X_train.shape[0])\n",
    "    print('Length valid:', X_valid.shape[0])\n",
    "    y_train = X_train[:,-1]\n",
    "    y_valid = X_valid[:,-1]\n",
    "    dtrain = xgb.DMatrix(X_train[:,:-1], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[:,:-1], y_valid)\n",
    "\n",
    "#     res = xgb.cv(params, dtrain, num_boost_round, nfold=10)\n",
    "#     print(res)\n",
    "#     print('running cross validation, disable standard deviation display')\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[:,:-1]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[:,:-1]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    training_time = round((time.time() - start_time)/60, 2)\n",
    "    print('Training time: {} minutes'.format(training_time))\n",
    "\n",
    "    print(gbm)\n",
    "    \n",
    "#     score = f1_score(test[target], test_prediction.tolist())\n",
    "    score = roc_auc_score(test[:,-1].tolist(), test_prediction.tolist())\n",
    "    \n",
    "#     print('f1 score: ', score)\n",
    "    print('roc_auc_score: ', score)\n",
    "\n",
    "    # To save logs\n",
    "    explog = {}\n",
    "#     explog['features'] = features\n",
    "#     explog['target'] = target\n",
    "    explog['params'] = {}\n",
    "    explog['params']['objective'] = objective\n",
    "    explog['params']['booster'] = booster\n",
    "    explog['params']['eval_metric'] = eval_metric\n",
    "    explog['params']['eta'] = eta\n",
    "    explog['params']['max_depth'] = max_depth\n",
    "    explog['params']['subsample'] = subsample\n",
    "    explog['params']['colsample_bytree'] = colsample_bytree\n",
    "    explog['params']['silent'] = silent\n",
    "    explog['params']['seed'] = random_state\n",
    "    explog['params']['num_boost_round'] = num_boost_round\n",
    "    explog['params']['early_stopping_rounds'] = early_stopping_rounds\n",
    "    explog['params']['test_size'] = test_size\n",
    "    explog['length_train']= X_train.shape[0]\n",
    "    explog['length_valid']= X_valid.shape[0]\n",
    "    # explog['gbm_best_iteration']= \n",
    "    explog['score'] = score\n",
    "    explog['training_time'] = training_time\n",
    "\n",
    "    return test_prediction.tolist(), score, explog, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateLog(explog, logPath):\n",
    "    try:\n",
    "        with open(logPath, 'r') as f:\n",
    "            obob = json.load(f)\n",
    "        f.close()\n",
    "    except:\n",
    "        obob = []\n",
    "\n",
    "\n",
    "    obob.append(explog)\n",
    "\n",
    "    with open(logPath, 'w') as f:\n",
    "        json.dump(obob, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train:  4840\n",
      "Length of test:  538\n",
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 3, SUBSAMPLE: 0.7, COLSAMPLE_BY_TREE: 0.7\n",
      "Length train: 4356\n",
      "Length valid: 484\n",
      "[0]\ttrain-auc:0.660419\ttrain-logloss:0.684534\ttrain-error:0.369146\teval-auc:0.606268\teval-logloss:0.687412\teval-error:0.417355\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 100 rounds.\n",
      "[1]\ttrain-auc:0.669401\ttrain-logloss:0.677357\ttrain-error:0.36708\teval-auc:0.61099\teval-logloss:0.68293\teval-error:0.415289\n",
      "[2]\ttrain-auc:0.673226\ttrain-logloss:0.671681\ttrain-error:0.367998\teval-auc:0.606857\teval-logloss:0.680724\teval-error:0.417355\n",
      "[3]\ttrain-auc:0.676166\ttrain-logloss:0.666329\ttrain-error:0.365702\teval-auc:0.606396\teval-logloss:0.677707\teval-error:0.415289\n",
      "[4]\ttrain-auc:0.676581\ttrain-logloss:0.662192\ttrain-error:0.369146\teval-auc:0.605354\teval-logloss:0.675616\teval-error:0.404959\n",
      "[5]\ttrain-auc:0.677249\ttrain-logloss:0.658265\ttrain-error:0.367309\teval-auc:0.607634\teval-logloss:0.673535\teval-error:0.411157\n",
      "[6]\ttrain-auc:0.678491\ttrain-logloss:0.655366\ttrain-error:0.367769\teval-auc:0.610708\teval-logloss:0.671752\teval-error:0.404959\n",
      "[7]\ttrain-auc:0.679039\ttrain-logloss:0.652763\ttrain-error:0.364555\teval-auc:0.610648\teval-logloss:0.67079\teval-error:0.39876\n",
      "[8]\ttrain-auc:0.681342\ttrain-logloss:0.650236\ttrain-error:0.365702\teval-auc:0.615182\teval-logloss:0.669628\teval-error:0.407025\n",
      "[9]\ttrain-auc:0.681513\ttrain-logloss:0.648234\ttrain-error:0.366162\teval-auc:0.615037\teval-logloss:0.669214\teval-error:0.409091\n",
      "[10]\ttrain-auc:0.685026\ttrain-logloss:0.646698\ttrain-error:0.36157\teval-auc:0.61876\teval-logloss:0.668871\teval-error:0.409091\n",
      "[11]\ttrain-auc:0.685874\ttrain-logloss:0.645018\ttrain-error:0.362029\teval-auc:0.617906\teval-logloss:0.668832\teval-error:0.409091\n",
      "[12]\ttrain-auc:0.688749\ttrain-logloss:0.643448\ttrain-error:0.359963\teval-auc:0.61736\teval-logloss:0.668498\teval-error:0.407025\n",
      "[13]\ttrain-auc:0.68871\ttrain-logloss:0.642029\ttrain-error:0.363636\teval-auc:0.618811\teval-logloss:0.66776\teval-error:0.413223\n",
      "[14]\ttrain-auc:0.689977\ttrain-logloss:0.640829\ttrain-error:0.366391\teval-auc:0.617018\teval-logloss:0.667955\teval-error:0.413223\n",
      "[15]\ttrain-auc:0.692636\ttrain-logloss:0.639579\ttrain-error:0.363866\teval-auc:0.614841\teval-logloss:0.668193\teval-error:0.407025\n",
      "[16]\ttrain-auc:0.692796\ttrain-logloss:0.638753\ttrain-error:0.363407\teval-auc:0.614388\teval-logloss:0.668237\teval-error:0.407025\n",
      "[17]\ttrain-auc:0.694164\ttrain-logloss:0.637842\ttrain-error:0.362718\teval-auc:0.614474\teval-logloss:0.66907\teval-error:0.411157\n",
      "[18]\ttrain-auc:0.696374\ttrain-logloss:0.636672\ttrain-error:0.357668\teval-auc:0.613227\teval-logloss:0.669337\teval-error:0.411157\n",
      "[19]\ttrain-auc:0.696513\ttrain-logloss:0.635767\ttrain-error:0.358356\teval-auc:0.613611\teval-logloss:0.669326\teval-error:0.404959\n",
      "[20]\ttrain-auc:0.698369\ttrain-logloss:0.634731\ttrain-error:0.357438\teval-auc:0.611938\teval-logloss:0.669546\teval-error:0.404959\n",
      "[21]\ttrain-auc:0.69897\ttrain-logloss:0.633818\ttrain-error:0.356061\teval-auc:0.611767\teval-logloss:0.669742\teval-error:0.413223\n",
      "[22]\ttrain-auc:0.698559\ttrain-logloss:0.632984\ttrain-error:0.355601\teval-auc:0.613662\teval-logloss:0.669169\teval-error:0.413223\n",
      "[23]\ttrain-auc:0.700408\ttrain-logloss:0.632155\ttrain-error:0.357208\teval-auc:0.615302\teval-logloss:0.668989\teval-error:0.415289\n",
      "[24]\ttrain-auc:0.701291\ttrain-logloss:0.631398\ttrain-error:0.357208\teval-auc:0.614747\teval-logloss:0.669329\teval-error:0.413223\n",
      "[25]\ttrain-auc:0.701551\ttrain-logloss:0.630685\ttrain-error:0.35652\teval-auc:0.615396\teval-logloss:0.669343\teval-error:0.411157\n",
      "[26]\ttrain-auc:0.701332\ttrain-logloss:0.630045\ttrain-error:0.356749\teval-auc:0.615575\teval-logloss:0.669451\teval-error:0.411157\n",
      "[27]\ttrain-auc:0.702723\ttrain-logloss:0.629452\ttrain-error:0.356749\teval-auc:0.615481\teval-logloss:0.669512\teval-error:0.413223\n",
      "[28]\ttrain-auc:0.703143\ttrain-logloss:0.629018\ttrain-error:0.356061\teval-auc:0.616941\teval-logloss:0.668761\teval-error:0.409091\n",
      "[29]\ttrain-auc:0.704731\ttrain-logloss:0.62817\ttrain-error:0.353306\teval-auc:0.619076\teval-logloss:0.668249\teval-error:0.404959\n",
      "[30]\ttrain-auc:0.705514\ttrain-logloss:0.627659\ttrain-error:0.353306\teval-auc:0.618444\teval-logloss:0.668937\teval-error:0.402893\n",
      "[31]\ttrain-auc:0.705458\ttrain-logloss:0.627171\ttrain-error:0.351928\teval-auc:0.617556\teval-logloss:0.669153\teval-error:0.400826\n",
      "[32]\ttrain-auc:0.706624\ttrain-logloss:0.626488\ttrain-error:0.351928\teval-auc:0.616429\teval-logloss:0.670178\teval-error:0.407025\n",
      "[33]\ttrain-auc:0.707649\ttrain-logloss:0.625771\ttrain-error:0.35124\teval-auc:0.617351\teval-logloss:0.670512\teval-error:0.407025\n",
      "[34]\ttrain-auc:0.708332\ttrain-logloss:0.625015\ttrain-error:0.351469\teval-auc:0.617573\teval-logloss:0.669944\teval-error:0.402893\n",
      "[35]\ttrain-auc:0.709418\ttrain-logloss:0.624362\ttrain-error:0.353076\teval-auc:0.618256\teval-logloss:0.669782\teval-error:0.400826\n",
      "[36]\ttrain-auc:0.710272\ttrain-logloss:0.623959\ttrain-error:0.352388\teval-auc:0.617659\teval-logloss:0.669851\teval-error:0.400826\n",
      "[37]\ttrain-auc:0.710777\ttrain-logloss:0.623602\ttrain-error:0.352158\teval-auc:0.617949\teval-logloss:0.669578\teval-error:0.400826\n",
      "[38]\ttrain-auc:0.711008\ttrain-logloss:0.622923\ttrain-error:0.350781\teval-auc:0.618495\teval-logloss:0.669533\teval-error:0.400826\n",
      "[39]\ttrain-auc:0.712016\ttrain-logloss:0.622431\ttrain-error:0.35101\teval-auc:0.617308\teval-logloss:0.670044\teval-error:0.400826\n",
      "[40]\ttrain-auc:0.712315\ttrain-logloss:0.622107\ttrain-error:0.351699\teval-auc:0.617095\teval-logloss:0.670307\teval-error:0.400826\n",
      "[41]\ttrain-auc:0.713027\ttrain-logloss:0.621481\ttrain-error:0.35124\teval-auc:0.61841\teval-logloss:0.670301\teval-error:0.404959\n",
      "[42]\ttrain-auc:0.713597\ttrain-logloss:0.621001\ttrain-error:0.350781\teval-auc:0.617334\teval-logloss:0.670706\teval-error:0.407025\n",
      "[43]\ttrain-auc:0.71479\ttrain-logloss:0.620351\ttrain-error:0.350321\teval-auc:0.616233\teval-logloss:0.670988\teval-error:0.39876\n",
      "[44]\ttrain-auc:0.715117\ttrain-logloss:0.620008\ttrain-error:0.349403\teval-auc:0.616113\teval-logloss:0.670911\teval-error:0.402893\n",
      "[45]\ttrain-auc:0.715844\ttrain-logloss:0.619581\ttrain-error:0.348026\teval-auc:0.616045\teval-logloss:0.670885\teval-error:0.402893\n",
      "[46]\ttrain-auc:0.71677\ttrain-logloss:0.619051\ttrain-error:0.348255\teval-auc:0.618325\teval-logloss:0.670429\teval-error:0.400826\n",
      "[47]\ttrain-auc:0.716947\ttrain-logloss:0.618778\ttrain-error:0.348255\teval-auc:0.618103\teval-logloss:0.670678\teval-error:0.396694\n",
      "[48]\ttrain-auc:0.717497\ttrain-logloss:0.618165\ttrain-error:0.347337\teval-auc:0.618572\teval-logloss:0.671045\teval-error:0.396694\n",
      "[49]\ttrain-auc:0.717929\ttrain-logloss:0.617882\ttrain-error:0.347567\teval-auc:0.618846\teval-logloss:0.670891\teval-error:0.396694\n",
      "[50]\ttrain-auc:0.718767\ttrain-logloss:0.617348\ttrain-error:0.347796\teval-auc:0.619828\teval-logloss:0.670918\teval-error:0.39876\n",
      "[51]\ttrain-auc:0.719556\ttrain-logloss:0.616922\ttrain-error:0.347337\teval-auc:0.621382\teval-logloss:0.670337\teval-error:0.39876\n",
      "[52]\ttrain-auc:0.71982\ttrain-logloss:0.616672\ttrain-error:0.34596\teval-auc:0.621621\teval-logloss:0.670315\teval-error:0.39876\n",
      "[53]\ttrain-auc:0.72064\ttrain-logloss:0.616181\ttrain-error:0.347107\teval-auc:0.624199\teval-logloss:0.669716\teval-error:0.39876\n",
      "[54]\ttrain-auc:0.720627\ttrain-logloss:0.616004\ttrain-error:0.347796\teval-auc:0.624814\teval-logloss:0.669652\teval-error:0.39876\n",
      "[55]\ttrain-auc:0.721169\ttrain-logloss:0.61552\ttrain-error:0.346648\teval-auc:0.625241\teval-logloss:0.669832\teval-error:0.39876\n",
      "[56]\ttrain-auc:0.722042\ttrain-logloss:0.61505\ttrain-error:0.348255\teval-auc:0.626847\teval-logloss:0.669842\teval-error:0.39876\n",
      "[57]\ttrain-auc:0.723069\ttrain-logloss:0.61445\ttrain-error:0.348026\teval-auc:0.625771\teval-logloss:0.670431\teval-error:0.404959\n",
      "[58]\ttrain-auc:0.723377\ttrain-logloss:0.614111\ttrain-error:0.348485\teval-auc:0.62548\teval-logloss:0.670845\teval-error:0.402893\n",
      "[59]\ttrain-auc:0.723749\ttrain-logloss:0.613851\ttrain-error:0.348485\teval-auc:0.625771\teval-logloss:0.670535\teval-error:0.402893\n",
      "[60]\ttrain-auc:0.724925\ttrain-logloss:0.613153\ttrain-error:0.347567\teval-auc:0.624507\teval-logloss:0.671188\teval-error:0.404959\n",
      "[61]\ttrain-auc:0.725398\ttrain-logloss:0.612562\ttrain-error:0.345271\teval-auc:0.622867\teval-logloss:0.671966\teval-error:0.402893\n",
      "[62]\ttrain-auc:0.726039\ttrain-logloss:0.61212\ttrain-error:0.343664\teval-auc:0.62437\teval-logloss:0.671887\teval-error:0.402893\n",
      "[63]\ttrain-auc:0.726634\ttrain-logloss:0.611749\ttrain-error:0.343434\teval-auc:0.624737\teval-logloss:0.671529\teval-error:0.402893\n",
      "[64]\ttrain-auc:0.727948\ttrain-logloss:0.611095\ttrain-error:0.342516\teval-auc:0.623721\teval-logloss:0.671838\teval-error:0.411157\n",
      "[65]\ttrain-auc:0.728893\ttrain-logloss:0.610524\ttrain-error:0.342975\teval-auc:0.622791\teval-logloss:0.672218\teval-error:0.407025\n",
      "[66]\ttrain-auc:0.729619\ttrain-logloss:0.610112\ttrain-error:0.342975\teval-auc:0.622261\teval-logloss:0.673031\teval-error:0.409091\n",
      "[67]\ttrain-auc:0.730845\ttrain-logloss:0.609572\ttrain-error:0.340909\teval-auc:0.62285\teval-logloss:0.672394\teval-error:0.413223\n",
      "[68]\ttrain-auc:0.731048\ttrain-logloss:0.609343\ttrain-error:0.34068\teval-auc:0.622406\teval-logloss:0.672697\teval-error:0.413223\n",
      "[69]\ttrain-auc:0.731325\ttrain-logloss:0.609079\ttrain-error:0.343434\teval-auc:0.622133\teval-logloss:0.672749\teval-error:0.411157\n",
      "[70]\ttrain-auc:0.731733\ttrain-logloss:0.608758\ttrain-error:0.342746\teval-auc:0.621962\teval-logloss:0.672967\teval-error:0.411157\n",
      "[71]\ttrain-auc:0.732188\ttrain-logloss:0.608318\ttrain-error:0.340909\teval-auc:0.622406\teval-logloss:0.672677\teval-error:0.413223\n",
      "[72]\ttrain-auc:0.732356\ttrain-logloss:0.608149\ttrain-error:0.339991\teval-auc:0.622389\teval-logloss:0.672634\teval-error:0.411157\n",
      "[73]\ttrain-auc:0.732595\ttrain-logloss:0.607875\ttrain-error:0.339532\teval-auc:0.622321\teval-logloss:0.6725\teval-error:0.411157\n",
      "[74]\ttrain-auc:0.733239\ttrain-logloss:0.607593\ttrain-error:0.339991\teval-auc:0.622611\teval-logloss:0.672357\teval-error:0.413223\n",
      "[75]\ttrain-auc:0.734602\ttrain-logloss:0.606766\ttrain-error:0.341139\teval-auc:0.621518\teval-logloss:0.672709\teval-error:0.407025\n",
      "[76]\ttrain-auc:0.735034\ttrain-logloss:0.606205\ttrain-error:0.341139\teval-auc:0.621569\teval-logloss:0.673579\teval-error:0.404959\n",
      "[77]\ttrain-auc:0.735394\ttrain-logloss:0.605965\ttrain-error:0.34022\teval-auc:0.621177\teval-logloss:0.673684\teval-error:0.404959\n",
      "[78]\ttrain-auc:0.735545\ttrain-logloss:0.605743\ttrain-error:0.34022\teval-auc:0.621928\teval-logloss:0.673286\teval-error:0.404959\n",
      "[79]\ttrain-auc:0.735739\ttrain-logloss:0.605526\ttrain-error:0.339532\teval-auc:0.622594\teval-logloss:0.673048\teval-error:0.404959\n",
      "[80]\ttrain-auc:0.736034\ttrain-logloss:0.605313\ttrain-error:0.337466\teval-auc:0.62256\teval-logloss:0.673179\teval-error:0.404959\n",
      "[81]\ttrain-auc:0.736864\ttrain-logloss:0.604725\ttrain-error:0.338843\teval-auc:0.621587\teval-logloss:0.673383\teval-error:0.404959\n",
      "[82]\ttrain-auc:0.737318\ttrain-logloss:0.604523\ttrain-error:0.338154\teval-auc:0.621552\teval-logloss:0.673609\teval-error:0.404959\n",
      "[83]\ttrain-auc:0.737584\ttrain-logloss:0.60424\ttrain-error:0.339073\teval-auc:0.621587\teval-logloss:0.673514\teval-error:0.404959\n",
      "[84]\ttrain-auc:0.737748\ttrain-logloss:0.604076\ttrain-error:0.338613\teval-auc:0.622133\teval-logloss:0.673216\teval-error:0.404959\n",
      "[85]\ttrain-auc:0.738\ttrain-logloss:0.603897\ttrain-error:0.338154\teval-auc:0.622133\teval-logloss:0.673261\teval-error:0.402893\n",
      "[86]\ttrain-auc:0.7381\ttrain-logloss:0.60354\ttrain-error:0.338843\teval-auc:0.621791\teval-logloss:0.673638\teval-error:0.402893\n",
      "[87]\ttrain-auc:0.739026\ttrain-logloss:0.603103\ttrain-error:0.337695\teval-auc:0.622099\teval-logloss:0.67335\teval-error:0.404959\n",
      "[88]\ttrain-auc:0.739496\ttrain-logloss:0.602875\ttrain-error:0.337925\teval-auc:0.621638\teval-logloss:0.673348\teval-error:0.402893\n",
      "[89]\ttrain-auc:0.739848\ttrain-logloss:0.602683\ttrain-error:0.337925\teval-auc:0.621877\teval-logloss:0.673306\teval-error:0.402893\n",
      "[90]\ttrain-auc:0.739962\ttrain-logloss:0.602478\ttrain-error:0.337236\teval-auc:0.62186\teval-logloss:0.673251\teval-error:0.402893\n",
      "[91]\ttrain-auc:0.740355\ttrain-logloss:0.602172\ttrain-error:0.337006\teval-auc:0.62227\teval-logloss:0.673059\teval-error:0.402893\n",
      "[92]\ttrain-auc:0.740845\ttrain-logloss:0.601685\ttrain-error:0.336777\teval-auc:0.622355\teval-logloss:0.673035\teval-error:0.402893\n",
      "[93]\ttrain-auc:0.741228\ttrain-logloss:0.601305\ttrain-error:0.335629\teval-auc:0.62168\teval-logloss:0.673508\teval-error:0.400826\n",
      "[94]\ttrain-auc:0.742213\ttrain-logloss:0.600667\ttrain-error:0.333792\teval-auc:0.621911\teval-logloss:0.673347\teval-error:0.400826\n",
      "[95]\ttrain-auc:0.742739\ttrain-logloss:0.60035\ttrain-error:0.333104\teval-auc:0.621843\teval-logloss:0.673378\teval-error:0.400826\n",
      "[96]\ttrain-auc:0.743459\ttrain-logloss:0.599792\ttrain-error:0.331726\teval-auc:0.621254\teval-logloss:0.673837\teval-error:0.400826\n",
      "[97]\ttrain-auc:0.74409\ttrain-logloss:0.599491\ttrain-error:0.331726\teval-auc:0.621544\teval-logloss:0.673503\teval-error:0.396694\n",
      "[98]\ttrain-auc:0.744561\ttrain-logloss:0.599154\ttrain-error:0.332185\teval-auc:0.621493\teval-logloss:0.673616\teval-error:0.394628\n",
      "[99]\ttrain-auc:0.744913\ttrain-logloss:0.598989\ttrain-error:0.332185\teval-auc:0.621117\teval-logloss:0.673831\teval-error:0.394628\n",
      "[100]\ttrain-auc:0.74605\ttrain-logloss:0.598199\ttrain-error:0.329431\teval-auc:0.620203\teval-logloss:0.674416\teval-error:0.39876\n",
      "[101]\ttrain-auc:0.746204\ttrain-logloss:0.597985\ttrain-error:0.330119\teval-auc:0.619298\teval-logloss:0.674956\teval-error:0.402893\n",
      "[102]\ttrain-auc:0.746763\ttrain-logloss:0.597514\ttrain-error:0.329431\teval-auc:0.619588\teval-logloss:0.675273\teval-error:0.402893\n",
      "[103]\ttrain-auc:0.747037\ttrain-logloss:0.597275\ttrain-error:0.329201\teval-auc:0.619742\teval-logloss:0.675408\teval-error:0.402893\n",
      "[104]\ttrain-auc:0.747367\ttrain-logloss:0.597019\ttrain-error:0.328972\teval-auc:0.619588\teval-logloss:0.675582\teval-error:0.402893\n",
      "[105]\ttrain-auc:0.747796\ttrain-logloss:0.596774\ttrain-error:0.328742\teval-auc:0.619144\teval-logloss:0.675767\teval-error:0.407025\n",
      "[106]\ttrain-auc:0.748959\ttrain-logloss:0.596449\ttrain-error:0.32966\teval-auc:0.618769\teval-logloss:0.675269\teval-error:0.407025\n",
      "[107]\ttrain-auc:0.749991\ttrain-logloss:0.595819\ttrain-error:0.328283\teval-auc:0.618991\teval-logloss:0.675017\teval-error:0.409091\n",
      "[108]\ttrain-auc:0.750149\ttrain-logloss:0.595621\ttrain-error:0.327824\teval-auc:0.618461\teval-logloss:0.675466\teval-error:0.409091\n",
      "[109]\ttrain-auc:0.750471\ttrain-logloss:0.595231\ttrain-error:0.326676\teval-auc:0.618794\teval-logloss:0.675437\teval-error:0.402893\n",
      "[110]\ttrain-auc:0.75117\ttrain-logloss:0.594753\ttrain-error:0.32438\teval-auc:0.619221\teval-logloss:0.675487\teval-error:0.404959\n",
      "[111]\ttrain-auc:0.751759\ttrain-logloss:0.594342\ttrain-error:0.32438\teval-auc:0.618828\teval-logloss:0.675494\teval-error:0.407025\n",
      "[112]\ttrain-auc:0.752231\ttrain-logloss:0.593902\ttrain-error:0.323921\teval-auc:0.61929\teval-logloss:0.675577\teval-error:0.409091\n",
      "[113]\ttrain-auc:0.752657\ttrain-logloss:0.593779\ttrain-error:0.323921\teval-auc:0.619477\teval-logloss:0.675568\teval-error:0.409091\n",
      "[114]\ttrain-auc:0.75276\ttrain-logloss:0.593687\ttrain-error:0.32461\teval-auc:0.619751\teval-logloss:0.675606\teval-error:0.411157\n",
      "[115]\ttrain-auc:0.753747\ttrain-logloss:0.593016\ttrain-error:0.32438\teval-auc:0.620912\teval-logloss:0.675417\teval-error:0.413223\n",
      "[116]\ttrain-auc:0.753956\ttrain-logloss:0.592771\ttrain-error:0.32438\teval-auc:0.621151\teval-logloss:0.675499\teval-error:0.413223\n",
      "[117]\ttrain-auc:0.754861\ttrain-logloss:0.59251\ttrain-error:0.323462\teval-auc:0.62139\teval-logloss:0.675239\teval-error:0.411157\n",
      "[118]\ttrain-auc:0.75508\ttrain-logloss:0.59222\ttrain-error:0.323691\teval-auc:0.621185\teval-logloss:0.675551\teval-error:0.411157\n",
      "[119]\ttrain-auc:0.755343\ttrain-logloss:0.591927\ttrain-error:0.322314\teval-auc:0.620929\teval-logloss:0.676118\teval-error:0.411157\n",
      "[120]\ttrain-auc:0.755559\ttrain-logloss:0.591678\ttrain-error:0.322084\teval-auc:0.620912\teval-logloss:0.676395\teval-error:0.407025\n",
      "[121]\ttrain-auc:0.755673\ttrain-logloss:0.591407\ttrain-error:0.321625\teval-auc:0.621185\teval-logloss:0.676617\teval-error:0.407025\n",
      "[122]\ttrain-auc:0.756047\ttrain-logloss:0.591161\ttrain-error:0.321625\teval-auc:0.620861\teval-logloss:0.676769\teval-error:0.407025\n",
      "[123]\ttrain-auc:0.756365\ttrain-logloss:0.59096\ttrain-error:0.320018\teval-auc:0.621117\teval-logloss:0.67662\teval-error:0.407025\n",
      "[124]\ttrain-auc:0.756869\ttrain-logloss:0.590646\ttrain-error:0.320248\teval-auc:0.622159\teval-logloss:0.676221\teval-error:0.404959\n",
      "[125]\ttrain-auc:0.757897\ttrain-logloss:0.590126\ttrain-error:0.320248\teval-auc:0.623747\teval-logloss:0.675828\teval-error:0.409091\n",
      "[126]\ttrain-auc:0.758834\ttrain-logloss:0.589455\ttrain-error:0.320018\teval-auc:0.622312\teval-logloss:0.676368\teval-error:0.407025\n",
      "[127]\ttrain-auc:0.759104\ttrain-logloss:0.589239\ttrain-error:0.320018\teval-auc:0.621988\teval-logloss:0.676614\teval-error:0.413223\n",
      "[128]\ttrain-auc:0.759623\ttrain-logloss:0.588921\ttrain-error:0.320248\teval-auc:0.622808\teval-logloss:0.67601\teval-error:0.411157\n",
      "[129]\ttrain-auc:0.759775\ttrain-logloss:0.588628\ttrain-error:0.3191\teval-auc:0.622415\teval-logloss:0.676349\teval-error:0.411157\n",
      "[130]\ttrain-auc:0.760595\ttrain-logloss:0.588093\ttrain-error:0.317723\teval-auc:0.622756\teval-logloss:0.676205\teval-error:0.409091\n",
      "[131]\ttrain-auc:0.760706\ttrain-logloss:0.587878\ttrain-error:0.317952\teval-auc:0.622893\teval-logloss:0.676281\teval-error:0.400826\n",
      "[132]\ttrain-auc:0.761565\ttrain-logloss:0.587413\ttrain-error:0.318641\teval-auc:0.622159\teval-logloss:0.676649\teval-error:0.409091\n",
      "[133]\ttrain-auc:0.762062\ttrain-logloss:0.587112\ttrain-error:0.318411\teval-auc:0.62139\teval-logloss:0.676833\teval-error:0.409091\n",
      "[134]\ttrain-auc:0.762544\ttrain-logloss:0.586715\ttrain-error:0.317034\teval-auc:0.622603\teval-logloss:0.675944\teval-error:0.409091\n",
      "[135]\ttrain-auc:0.763103\ttrain-logloss:0.586308\ttrain-error:0.316116\teval-auc:0.622842\teval-logloss:0.676441\teval-error:0.409091\n",
      "[136]\ttrain-auc:0.763235\ttrain-logloss:0.586069\ttrain-error:0.316345\teval-auc:0.623388\teval-logloss:0.67647\teval-error:0.409091\n",
      "[137]\ttrain-auc:0.763761\ttrain-logloss:0.585762\ttrain-error:0.316116\teval-auc:0.6232\teval-logloss:0.676472\teval-error:0.409091\n",
      "[138]\ttrain-auc:0.763859\ttrain-logloss:0.585226\ttrain-error:0.317493\teval-auc:0.623235\teval-logloss:0.676969\teval-error:0.413223\n",
      "[139]\ttrain-auc:0.764193\ttrain-logloss:0.584953\ttrain-error:0.317264\teval-auc:0.622791\teval-logloss:0.677536\teval-error:0.413223\n",
      "[140]\ttrain-auc:0.764293\ttrain-logloss:0.58463\ttrain-error:0.315427\teval-auc:0.622637\teval-logloss:0.677831\teval-error:0.415289\n",
      "[141]\ttrain-auc:0.765175\ttrain-logloss:0.584155\ttrain-error:0.315197\teval-auc:0.6225\teval-logloss:0.677784\teval-error:0.417355\n",
      "[142]\ttrain-auc:0.765667\ttrain-logloss:0.583703\ttrain-error:0.315657\teval-auc:0.622466\teval-logloss:0.677752\teval-error:0.417355\n",
      "[143]\ttrain-auc:0.766059\ttrain-logloss:0.583471\ttrain-error:0.315657\teval-auc:0.622329\teval-logloss:0.678093\teval-error:0.411157\n",
      "[144]\ttrain-auc:0.766559\ttrain-logloss:0.583052\ttrain-error:0.314509\teval-auc:0.620809\teval-logloss:0.679078\teval-error:0.409091\n",
      "[145]\ttrain-auc:0.766831\ttrain-logloss:0.58272\ttrain-error:0.314738\teval-auc:0.620895\teval-logloss:0.679236\teval-error:0.409091\n",
      "[146]\ttrain-auc:0.767592\ttrain-logloss:0.582265\ttrain-error:0.314509\teval-auc:0.620844\teval-logloss:0.679008\teval-error:0.409091\n",
      "[147]\ttrain-auc:0.767781\ttrain-logloss:0.582029\ttrain-error:0.314279\teval-auc:0.620809\teval-logloss:0.67875\teval-error:0.409091\n",
      "[148]\ttrain-auc:0.768386\ttrain-logloss:0.581736\ttrain-error:0.313361\teval-auc:0.619862\teval-logloss:0.679303\teval-error:0.411157\n",
      "[149]\ttrain-auc:0.768474\ttrain-logloss:0.581608\ttrain-error:0.31405\teval-auc:0.618547\teval-logloss:0.679866\teval-error:0.411157\n",
      "[150]\ttrain-auc:0.769082\ttrain-logloss:0.581147\ttrain-error:0.31405\teval-auc:0.619315\teval-logloss:0.679897\teval-error:0.404959\n",
      "[151]\ttrain-auc:0.769303\ttrain-logloss:0.580989\ttrain-error:0.31359\teval-auc:0.618478\teval-logloss:0.680462\teval-error:0.402893\n",
      "[152]\ttrain-auc:0.769173\ttrain-logloss:0.580753\ttrain-error:0.31359\teval-auc:0.618137\teval-logloss:0.681325\teval-error:0.402893\n",
      "[153]\ttrain-auc:0.76963\ttrain-logloss:0.580445\ttrain-error:0.312902\teval-auc:0.617864\teval-logloss:0.68148\teval-error:0.404959\n",
      "[154]\ttrain-auc:0.769953\ttrain-logloss:0.580177\ttrain-error:0.312672\teval-auc:0.61812\teval-logloss:0.68127\teval-error:0.402893\n",
      "[155]\ttrain-auc:0.770589\ttrain-logloss:0.579594\ttrain-error:0.311754\teval-auc:0.617488\teval-logloss:0.681752\teval-error:0.39876\n",
      "[156]\ttrain-auc:0.770737\ttrain-logloss:0.579421\ttrain-error:0.311295\teval-auc:0.617642\teval-logloss:0.681676\teval-error:0.39876\n",
      "[157]\ttrain-auc:0.771259\ttrain-logloss:0.579065\ttrain-error:0.311983\teval-auc:0.616344\teval-logloss:0.682146\teval-error:0.400826\n",
      "[158]\ttrain-auc:0.77151\ttrain-logloss:0.578989\ttrain-error:0.311295\teval-auc:0.616327\teval-logloss:0.682034\teval-error:0.400826\n",
      "[159]\ttrain-auc:0.771885\ttrain-logloss:0.578737\ttrain-error:0.310376\teval-auc:0.61718\teval-logloss:0.681509\teval-error:0.400826\n",
      "[160]\ttrain-auc:0.772274\ttrain-logloss:0.578471\ttrain-error:0.310147\teval-auc:0.61742\teval-logloss:0.681276\teval-error:0.400826\n",
      "[161]\ttrain-auc:0.772473\ttrain-logloss:0.578217\ttrain-error:0.310606\teval-auc:0.617898\teval-logloss:0.68136\teval-error:0.39876\n",
      "[162]\ttrain-auc:0.77271\ttrain-logloss:0.577927\ttrain-error:0.309917\teval-auc:0.617505\teval-logloss:0.681808\teval-error:0.400826\n",
      "[163]\ttrain-auc:0.773199\ttrain-logloss:0.577499\ttrain-error:0.309688\teval-auc:0.61759\teval-logloss:0.682186\teval-error:0.400826\n",
      "[164]\ttrain-auc:0.773928\ttrain-logloss:0.577078\ttrain-error:0.308999\teval-auc:0.618478\teval-logloss:0.681839\teval-error:0.400826\n",
      "[165]\ttrain-auc:0.774901\ttrain-logloss:0.576577\ttrain-error:0.306703\teval-auc:0.617744\teval-logloss:0.681851\teval-error:0.402893\n",
      "[166]\ttrain-auc:0.775718\ttrain-logloss:0.576106\ttrain-error:0.306703\teval-auc:0.61853\teval-logloss:0.681925\teval-error:0.407025\n",
      "[167]\ttrain-auc:0.776226\ttrain-logloss:0.575786\ttrain-error:0.305326\teval-auc:0.618444\teval-logloss:0.6819\teval-error:0.409091\n",
      "[168]\ttrain-auc:0.776539\ttrain-logloss:0.575479\ttrain-error:0.305785\teval-auc:0.617642\teval-logloss:0.68253\teval-error:0.409091\n",
      "[169]\ttrain-auc:0.776621\ttrain-logloss:0.575348\ttrain-error:0.306474\teval-auc:0.617215\teval-logloss:0.682883\teval-error:0.409091\n",
      "[170]\ttrain-auc:0.77749\ttrain-logloss:0.574905\ttrain-error:0.304867\teval-auc:0.616446\teval-logloss:0.682853\teval-error:0.409091\n",
      "[171]\ttrain-auc:0.777476\ttrain-logloss:0.574623\ttrain-error:0.305785\teval-auc:0.615524\teval-logloss:0.683432\teval-error:0.411157\n",
      "[172]\ttrain-auc:0.777771\ttrain-logloss:0.574431\ttrain-error:0.305556\teval-auc:0.615131\teval-logloss:0.683634\teval-error:0.409091\n",
      "[173]\ttrain-auc:0.778545\ttrain-logloss:0.573929\ttrain-error:0.304637\teval-auc:0.616378\teval-logloss:0.683193\teval-error:0.404959\n",
      "[174]\ttrain-auc:0.779027\ttrain-logloss:0.573504\ttrain-error:0.30303\teval-auc:0.616771\teval-logloss:0.683126\teval-error:0.407025\n",
      "[175]\ttrain-auc:0.779103\ttrain-logloss:0.573404\ttrain-error:0.30303\teval-auc:0.616736\teval-logloss:0.683114\teval-error:0.402893\n",
      "[176]\ttrain-auc:0.778861\ttrain-logloss:0.573264\ttrain-error:0.302571\teval-auc:0.617146\teval-logloss:0.682762\teval-error:0.402893\n",
      "[177]\ttrain-auc:0.779492\ttrain-logloss:0.572902\ttrain-error:0.301194\teval-auc:0.617633\teval-logloss:0.68251\teval-error:0.411157\n",
      "[178]\ttrain-auc:0.780238\ttrain-logloss:0.572522\ttrain-error:0.299816\teval-auc:0.617513\teval-logloss:0.682031\teval-error:0.413223\n",
      "[179]\ttrain-auc:0.780639\ttrain-logloss:0.572095\ttrain-error:0.300505\teval-auc:0.618419\teval-logloss:0.681774\teval-error:0.409091\n",
      "[180]\ttrain-auc:0.781048\ttrain-logloss:0.571797\ttrain-error:0.300046\teval-auc:0.618384\teval-logloss:0.681608\teval-error:0.407025\n",
      "[181]\ttrain-auc:0.782364\ttrain-logloss:0.571304\ttrain-error:0.299357\teval-auc:0.618265\teval-logloss:0.681538\teval-error:0.411157\n",
      "[182]\ttrain-auc:0.782922\ttrain-logloss:0.570842\ttrain-error:0.299587\teval-auc:0.617445\teval-logloss:0.68204\teval-error:0.407025\n",
      "[183]\ttrain-auc:0.782986\ttrain-logloss:0.570697\ttrain-error:0.299816\teval-auc:0.617957\teval-logloss:0.681781\teval-error:0.407025\n",
      "[184]\ttrain-auc:0.78305\ttrain-logloss:0.57057\ttrain-error:0.299357\teval-auc:0.618333\teval-logloss:0.681556\teval-error:0.407025\n",
      "[185]\ttrain-auc:0.783181\ttrain-logloss:0.570475\ttrain-error:0.299128\teval-auc:0.617923\teval-logloss:0.681993\teval-error:0.407025\n",
      "[186]\ttrain-auc:0.783279\ttrain-logloss:0.570156\ttrain-error:0.298898\teval-auc:0.61847\teval-logloss:0.681555\teval-error:0.407025\n",
      "[187]\ttrain-auc:0.783555\ttrain-logloss:0.569991\ttrain-error:0.298209\teval-auc:0.617872\teval-logloss:0.682013\teval-error:0.409091\n",
      "[188]\ttrain-auc:0.783853\ttrain-logloss:0.569716\ttrain-error:0.299357\teval-auc:0.618504\teval-logloss:0.681524\teval-error:0.411157\n",
      "[189]\ttrain-auc:0.784194\ttrain-logloss:0.569456\ttrain-error:0.298439\teval-auc:0.618828\teval-logloss:0.681185\teval-error:0.411157\n",
      "[190]\ttrain-auc:0.784452\ttrain-logloss:0.569364\ttrain-error:0.297521\teval-auc:0.618863\teval-logloss:0.681068\teval-error:0.411157\n",
      "[191]\ttrain-auc:0.784838\ttrain-logloss:0.569101\ttrain-error:0.29798\teval-auc:0.61876\teval-logloss:0.681156\teval-error:0.404959\n",
      "[192]\ttrain-auc:0.785056\ttrain-logloss:0.568956\ttrain-error:0.296373\teval-auc:0.617855\teval-logloss:0.681663\teval-error:0.404959\n",
      "[193]\ttrain-auc:0.785311\ttrain-logloss:0.568513\ttrain-error:0.295225\teval-auc:0.617616\teval-logloss:0.682171\teval-error:0.411157\n",
      "[194]\ttrain-auc:0.785571\ttrain-logloss:0.568297\ttrain-error:0.294766\teval-auc:0.617326\teval-logloss:0.682593\teval-error:0.413223\n",
      "[195]\ttrain-auc:0.786114\ttrain-logloss:0.567807\ttrain-error:0.295225\teval-auc:0.616694\teval-logloss:0.683159\teval-error:0.415289\n",
      "[196]\ttrain-auc:0.787097\ttrain-logloss:0.56727\ttrain-error:0.295455\teval-auc:0.616147\teval-logloss:0.683358\teval-error:0.413223\n",
      "[197]\ttrain-auc:0.787347\ttrain-logloss:0.567127\ttrain-error:0.294995\teval-auc:0.615601\teval-logloss:0.683201\teval-error:0.417355\n",
      "[198]\ttrain-auc:0.787549\ttrain-logloss:0.566906\ttrain-error:0.295455\teval-auc:0.615686\teval-logloss:0.683639\teval-error:0.415289\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-auc:0.744561\ttrain-logloss:0.599154\ttrain-error:0.332185\teval-auc:0.621493\teval-logloss:0.673616\teval-error:0.394628\n",
      "\n",
      "Validating...\n",
      "Predict test set...\n",
      "Training time: 0.03 minutes\n",
      "<xgboost.core.Booster object at 0x11a858668>\n",
      "roc_auc_score:  0.657477863863\n",
      "Score:  0.657477863863\n"
     ]
    }
   ],
   "source": [
    "X_y = np.vstack((X.T, y)).T\n",
    "train, test = train_test_split(X_y, test_size=0.1)\n",
    "\n",
    "features = newcolumns[3:]\n",
    "target = 'revisit_intention'\n",
    "\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "# print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "\n",
    "test_prediction, score, explog, gbm = run_xgb(train, test)\n",
    "print('Score: ', score)\n",
    "\n",
    "logPath = '../result/results.json'\n",
    "\n",
    "explog['dataset']= datadir\n",
    "explog['ts']= time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "updateLog(explog, logPath)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
